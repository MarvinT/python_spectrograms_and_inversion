{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iPython specific stuff\n",
    "%matplotlib inline\n",
    "import IPython.display\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "\n",
    "# Packages we're using\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, lfilter\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Most of the Spectrograms and Inversion are taken from: https://gist.github.com/kastnerkyle/179d6e9a88202ab0a2fe\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def overlap(X, window_size, window_step):\n",
    "    \"\"\"\n",
    "    Create an overlapped version of X\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray, shape=(n_samples,)\n",
    "        Input signal to window and overlap\n",
    "    window_size : int\n",
    "        Size of windows to take\n",
    "    window_step : int\n",
    "        Step size between windows\n",
    "    Returns\n",
    "    -------\n",
    "    X_strided : shape=(n_windows, window_size)\n",
    "        2D array of overlapped X\n",
    "    \"\"\"\n",
    "    if window_size % 2 != 0:\n",
    "        raise ValueError(\"Window size must be even!\")\n",
    "    # Make sure there are an even number of windows before stridetricks\n",
    "    append = np.zeros((window_size - len(X) % window_size))\n",
    "    X = np.hstack((X, append))\n",
    "\n",
    "    ws = window_size\n",
    "    ss = window_step\n",
    "    a = X\n",
    "\n",
    "    valid = len(a) - ws\n",
    "    nw = (valid) // ss\n",
    "    out = np.ndarray((nw,ws),dtype = a.dtype)\n",
    "\n",
    "    for i in xrange(nw):\n",
    "        # \"slide\" the window along the samples\n",
    "        start = i * ss\n",
    "        stop = start + ws\n",
    "        out[i] = a[start : stop]\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def stft(X, fftsize=128, step=65, mean_normalize=True, real=False,\n",
    "         compute_onesided=True):\n",
    "    \"\"\"\n",
    "    Compute STFT for 1D real valued input X\n",
    "    \"\"\"\n",
    "    if real:\n",
    "        local_fft = np.fft.rfft\n",
    "        cut = -1\n",
    "    else:\n",
    "        local_fft = np.fft.fft\n",
    "        cut = None\n",
    "    if compute_onesided:\n",
    "        cut = fftsize // 2\n",
    "    if mean_normalize:\n",
    "        X -= X.mean()\n",
    "\n",
    "    X = overlap(X, fftsize, step)\n",
    "    \n",
    "    size = fftsize\n",
    "    win = 0.54 - .46 * np.cos(2 * np.pi * np.arange(size) / (size - 1))\n",
    "    X = X * win[None]\n",
    "    X = local_fft(X)[:, :cut]\n",
    "    return X\n",
    "\n",
    "def pretty_spectrogram(d,log = True, thresh= 5, fft_size = 512, step_size = 64):\n",
    "    \"\"\"\n",
    "    creates a spectrogram\n",
    "    log: take the log of the spectrgram\n",
    "    thresh: threshold minimum power for log spectrogram\n",
    "    \"\"\"\n",
    "    specgram = np.abs(stft(d, fftsize=fft_size, step=step_size, real=False,\n",
    "        compute_onesided=True))\n",
    "  \n",
    "    if log == True:\n",
    "        specgram /= specgram.max() # volume normalize to max 1\n",
    "        specgram = np.log10(specgram) # take log\n",
    "        specgram[specgram < -thresh] = -thresh # set anything less than the threshold as the threshold\n",
    "    else:\n",
    "        specgram[specgram < thresh] = thresh # set anything less than the threshold as the threshold\n",
    "    \n",
    "    return specgram\n",
    "\n",
    "# Also mostly modified or taken from https://gist.github.com/kastnerkyle/179d6e9a88202ab0a2fe\n",
    "def invert_pretty_spectrogram(X_s, log = True, fft_size = 512, step_size = 512/4, n_iter = 10):\n",
    "    \n",
    "    if log == True:\n",
    "        X_s = np.power(10, X_s)\n",
    "\n",
    "    X_s = np.concatenate([X_s, X_s[:, ::-1]], axis=1)\n",
    "    X_t = iterate_invert_spectrogram(X_s, fft_size, step_size, n_iter=n_iter)\n",
    "    return X_t\n",
    "\n",
    "def iterate_invert_spectrogram(X_s, fftsize, step, n_iter=10, verbose=False):\n",
    "    \"\"\"\n",
    "    Under MSR-LA License\n",
    "    Based on MATLAB implementation from Spectrogram Inversion Toolbox\n",
    "    References\n",
    "    ----------\n",
    "    D. Griffin and J. Lim. Signal estimation from modified\n",
    "    short-time Fourier transform. IEEE Trans. Acoust. Speech\n",
    "    Signal Process., 32(2):236-243, 1984.\n",
    "    Malcolm Slaney, Daniel Naar and Richard F. Lyon. Auditory\n",
    "    Model Inversion for Sound Separation. Proc. IEEE-ICASSP,\n",
    "    Adelaide, 1994, II.77-80.\n",
    "    Xinglei Zhu, G. Beauregard, L. Wyse. Real-Time Signal\n",
    "    Estimation from Modified Short-Time Fourier Transform\n",
    "    Magnitude Spectra. IEEE Transactions on Audio Speech and\n",
    "    Language Processing, 08/2007.\n",
    "    \"\"\"\n",
    "    reg = np.max(X_s) / 1E8\n",
    "    X_best = copy.deepcopy(X_s)\n",
    "    for i in range(n_iter):\n",
    "        if verbose:\n",
    "            print(\"Runnning iter %i\" % i)\n",
    "        if i == 0:\n",
    "            X_t = invert_spectrogram(X_best, step, calculate_offset=True,\n",
    "                                     set_zero_phase=True)\n",
    "        else:\n",
    "            X_t = invert_spectrogram(X_best, step, calculate_offset=True,\n",
    "                                     set_zero_phase=False)\n",
    "            \n",
    "        est = stft(X_t, fftsize=fftsize, step=step, compute_onesided=False)\n",
    "        phase = est / np.maximum(reg, np.abs(est))\n",
    "        X_best = X_s[:len(phase)] * phase[:len(X_s)]\n",
    "    X_t = invert_spectrogram(X_best, step, calculate_offset=True,\n",
    "                             set_zero_phase=False)\n",
    "    return np.real(X_t)\n",
    "\n",
    "def invert_spectrogram(X_s, step, calculate_offset=True, set_zero_phase=True):\n",
    "    \"\"\"\n",
    "    Under MSR-LA License\n",
    "    Based on MATLAB implementation from Spectrogram Inversion Toolbox\n",
    "    References\n",
    "    ----------\n",
    "    D. Griffin and J. Lim. Signal estimation from modified\n",
    "    short-time Fourier transform. IEEE Trans. Acoust. Speech\n",
    "    Signal Process., 32(2):236-243, 1984.\n",
    "    Malcolm Slaney, Daniel Naar and Richard F. Lyon. Auditory\n",
    "    Model Inversion for Sound Separation. Proc. IEEE-ICASSP,\n",
    "    Adelaide, 1994, II.77-80.\n",
    "    Xinglei Zhu, G. Beauregard, L. Wyse. Real-Time Signal\n",
    "    Estimation from Modified Short-Time Fourier Transform\n",
    "    Magnitude Spectra. IEEE Transactions on Audio Speech and\n",
    "    Language Processing, 08/2007.\n",
    "    \"\"\"\n",
    "    size = int(X_s.shape[1] // 2)\n",
    "    wave = np.zeros((X_s.shape[0] * step + size))\n",
    "    # Getting overflow warnings with 32 bit...\n",
    "    wave = wave.astype('float64')\n",
    "    total_windowing_sum = np.zeros((X_s.shape[0] * step + size))\n",
    "    win = 0.54 - .46 * np.cos(2 * np.pi * np.arange(size) / (size - 1))\n",
    "\n",
    "    est_start = int(size // 2) - 1\n",
    "    est_end = est_start + size\n",
    "    for i in range(X_s.shape[0]):\n",
    "        wave_start = int(step * i)\n",
    "        wave_end = wave_start + size\n",
    "        if set_zero_phase:\n",
    "            spectral_slice = X_s[i].real + 0j\n",
    "        else:\n",
    "            # already complex\n",
    "            spectral_slice = X_s[i]\n",
    "\n",
    "        # Don't need fftshift due to different impl.\n",
    "        wave_est = np.real(np.fft.ifft(spectral_slice))[::-1]\n",
    "        if calculate_offset and i > 0:\n",
    "            offset_size = size - step\n",
    "            if offset_size <= 0:\n",
    "                print(\"WARNING: Large step size >50\\% detected! \"\n",
    "                      \"This code works best with high overlap - try \"\n",
    "                      \"with 75% or greater\")\n",
    "                offset_size = step\n",
    "            offset = xcorr_offset(wave[wave_start:wave_start + offset_size],\n",
    "                                  wave_est[est_start:est_start + offset_size])\n",
    "        else:\n",
    "            offset = 0\n",
    "        wave[wave_start:wave_end] += win * wave_est[\n",
    "            est_start - offset:est_end - offset]\n",
    "        total_windowing_sum[wave_start:wave_end] += win\n",
    "    wave = np.real(wave) / (total_windowing_sum + 1E-6)\n",
    "    return wave\n",
    "\n",
    "def xcorr_offset(x1, x2):\n",
    "    \"\"\"\n",
    "    Under MSR-LA License\n",
    "    Based on MATLAB implementation from Spectrogram Inversion Toolbox\n",
    "    References\n",
    "    ----------\n",
    "    D. Griffin and J. Lim. Signal estimation from modified\n",
    "    short-time Fourier transform. IEEE Trans. Acoust. Speech\n",
    "    Signal Process., 32(2):236-243, 1984.\n",
    "    Malcolm Slaney, Daniel Naar and Richard F. Lyon. Auditory\n",
    "    Model Inversion for Sound Separation. Proc. IEEE-ICASSP,\n",
    "    Adelaide, 1994, II.77-80.\n",
    "    Xinglei Zhu, G. Beauregard, L. Wyse. Real-Time Signal\n",
    "    Estimation from Modified Short-Time Fourier Transform\n",
    "    Magnitude Spectra. IEEE Transactions on Audio Speech and\n",
    "    Language Processing, 08/2007.\n",
    "    \"\"\"\n",
    "    x1 = x1 - x1.mean()\n",
    "    x2 = x2 - x2.mean()\n",
    "    frame_size = len(x2)\n",
    "    half = frame_size // 2\n",
    "    corrs = np.convolve(x1.astype('float32'), x2[::-1].astype('float32'))\n",
    "    corrs[:half] = -1E30\n",
    "    corrs[-half:] = -1E30\n",
    "    offset = corrs.argmax() - len(x1)\n",
    "    return offset\n",
    "\n",
    "def freq_to_mel(f):\n",
    "    return 2595.*np.log10(1+(f/700.))\n",
    "def mel_to_freq(m):\n",
    "    return 700.0*(10.0**(m/2595.0)-1.0)\n",
    "\n",
    "def create_mel_filter_old(fft_size, n_freq_components = 64, start_freq = 300, end_freq = 8000):\n",
    "    \"\"\"\n",
    "    Creates a filter to convolve with the spectrogram to get out mels\n",
    "\n",
    "    \"\"\"\n",
    "    spec_size = fft_size/2\n",
    "    start_mel = freq_to_mel(start_freq)\n",
    "    end_mel = freq_to_mel(end_freq)\n",
    "    plt_spacing = []\n",
    "    # find our central channels from the spectrogram\n",
    "    for i in range(10000):\n",
    "        y = np.linspace(start_mel, end_mel, num=i, endpoint=False)\n",
    "        logp = mel_to_freq(y)\n",
    "        logp = logp/(rate/2/spec_size)\n",
    "        true_spacing = [int(i)-1 for i in np.ceil(logp)] \n",
    "        plt_spacing_mel = np.unique(true_spacing)\n",
    "        if len(plt_spacing_mel) == n_freq_components:\n",
    "            break\n",
    "    plt_spacing = plt_spacing_mel\n",
    "    if plt_spacing_mel[-1] == spec_size:\n",
    "        plt_spacing_mel[-1] = plt_spacing_mel[-1]-1\n",
    "    # make the filter\n",
    "    mel_filter = np.zeros((int(spec_size),n_freq_components))\n",
    "    # Create Filter\n",
    "    for i in range(len(plt_spacing)):  \n",
    "        if i > 0:\n",
    "            if plt_spacing[i-1] < plt_spacing[i] - 1:\n",
    "                # the first half of the window should start with zero\n",
    "                mel_filter[plt_spacing[i-1]:plt_spacing[i], i] = np.arange(0,1,1./(plt_spacing[i]-plt_spacing[i-1]))\n",
    "        if i < n_freq_components-1:\n",
    "            if plt_spacing[i+1] > plt_spacing[i]+1:\n",
    "                mel_filter[plt_spacing[i]:plt_spacing[i+1], i] = np.arange(0,1,1./(plt_spacing[i+1]-plt_spacing[i]))[::-1]\n",
    "        elif plt_spacing[i] < spec_size:\n",
    "            mel_filter[plt_spacing[i]:int(mel_to_freq(end_mel)/(rate/2/spec_size)), i] =  \\\n",
    "                np.arange(0,1,1./(int(mel_to_freq(end_mel)/(rate/2/spec_size))-plt_spacing[i]))[::-1]\n",
    "        mel_filter[plt_spacing[i], i] = 1\n",
    "    # Normalize filter\n",
    "    mel_filter = mel_filter / mel_filter.sum(axis=0)\n",
    "    # Create and normalize inversion filter\n",
    "    mel_inversion_filter = np.transpose(mel_filter) / np.transpose(mel_filter).sum(axis=0)\n",
    "    mel_inversion_filter[np.isnan(mel_inversion_filter)] = 0 # for when a row has a sum of 0\n",
    "\n",
    "    return mel_filter, mel_inversion_filter\n",
    "\n",
    "def make_mel(spectrogram, mel_filter, shorten_factor = 1):\n",
    "    mel_spec =np.transpose(mel_filter).dot(np.transpose(spectrogram))\n",
    "    mel_spec = scipy.ndimage.zoom(mel_spec.astype('float32'), [1, 1./shorten_factor]).astype('float16')\n",
    "    mel_spec = mel_spec[:,1:-1] # a little hacky but seemingly needed for clipping \n",
    "    return mel_spec\n",
    "\n",
    "def mel_to_spectrogram(mel_spec, mel_inversion_filter, spec_thresh, shorten_factor):\n",
    "    \"\"\"\n",
    "    takes in an mel spectrogram and returns a normal spectrogram for inversion \n",
    "    \"\"\"\n",
    "    mel_spec = (mel_spec+spec_thresh)\n",
    "    uncompressed_spec = np.transpose(np.transpose(mel_spec).dot(mel_inversion_filter))\n",
    "    uncompressed_spec = scipy.ndimage.zoom(uncompressed_spec.astype('float32'), [1,shorten_factor]).astype('float16')\n",
    "    uncompressed_spec = uncompressed_spec -4\n",
    "    return uncompressed_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_params(bandwidth, trim=5):\n",
    "    h = np.arange(bandwidth) + 1\n",
    "    w = bandwidth / h\n",
    "    w, idx = np.unique(w[::-1], return_index=True)\n",
    "    h = h[::-1][idx]\n",
    "    return zip(h, w)[trim:-trim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://github.com/jameslyons/python_speech_features\n",
    "\n",
    "def hz2mel(hz):\n",
    "    \"\"\"Convert a value in Hertz to Mels\n",
    "    :param hz: a value in Hz. This can also be a numpy array, conversion proceeds element-wise.\n",
    "    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n",
    "    \"\"\"\n",
    "    return 2595 * np.log10(1+hz/700.)\n",
    "    \n",
    "def mel2hz(mel):\n",
    "    \"\"\"Convert a value in Mels to Hertz\n",
    "    :param mel: a value in Mels. This can also be a numpy array, conversion proceeds element-wise.\n",
    "    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n",
    "    \"\"\"\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "\n",
    "def get_filterbanks(nfilt=20,nfft=512,samplerate=16000,lowfreq=0,highfreq=None):\n",
    "    \"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n",
    "    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n",
    "    :param nfilt: the number of filters in the filterbank, default 20.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param samplerate: the samplerate of the signal we are working with. Affects mel spacing.\n",
    "    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n",
    "    :param highfreq: highest band edge of mel filters, default samplerate/2\n",
    "    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "    \n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = hz2mel(lowfreq)\n",
    "    highmel = hz2mel(highfreq)\n",
    "    melpoints = np.linspace(lowmel,highmel,nfilt+2)\n",
    "    # our points are in Hz, but we use fft bins, so we have to convert\n",
    "    #  from Hz to fft bin number\n",
    "    bin = np.floor((nfft+1)*mel2hz(melpoints)/samplerate)\n",
    "\n",
    "    fbank = np.zeros([nfilt,nfft//2])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bin[j]), int(bin[j+1])):\n",
    "            fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "        for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "            fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "    return fbank\n",
    "\n",
    "def create_mel_filter(fft_size, n_freq_components = 64, start_freq = 300, end_freq = 8000, samplerate=44100):\n",
    "    \"\"\"\n",
    "    Creates a filter to convolve with the spectrogram to get out mels\n",
    "\n",
    "    \"\"\"\n",
    "    mel_inversion_filter = get_filterbanks(nfilt=n_freq_components, \n",
    "                                           nfft=fft_size, samplerate=samplerate, \n",
    "                                           lowfreq=start_freq, highfreq=end_freq)\n",
    "    # Normalize filter\n",
    "    mel_filter = mel_inversion_filter.T / mel_inversion_filter.sum(axis=1)\n",
    "    mel_filter[np.isnan(mel_filter)] = 0\n",
    "\n",
    "    return mel_filter, mel_inversion_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameters ###\n",
    "fft_size = 2048 # window size for the FFT\n",
    "step_size = fft_size/16 # distance to slide along the window (in time)\n",
    "spec_thresh = 4 # threshold for spectrograms (lower filters out more noise)\n",
    "lowcut = 500 # Hz # Low cut for our butter bandpass filter\n",
    "highcut = 15000 # Hz # High cut for our butter bandpass filter\n",
    "# For mels\n",
    "start_freq = 500 # Hz # What frequency to start sampling our melS from \n",
    "end_freq = 15000 # Hz # What frequency to stop sampling our melS from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grab your wav and filter it\n",
    "mywav = 'bushOffersPeace.wav'\n",
    "rate, data = wavfile.read(mywav)\n",
    "data = butter_bandpass_filter(data, lowcut, highcut, rate, order=1)\n",
    "# Only use a short clip for our demo\n",
    "if np.shape(data)[0]/float(rate) > 10:\n",
    "    data = data[0:rate*10] \n",
    "print 'Length in time (s): ', np.shape(data)[0]/float(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rate, orig_data = wavfile.read(mywav)\n",
    "orig_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.maxint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spect_bps = rate/float(step_size)\n",
    "print spect_bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wav_spectrogram = pretty_spectrogram(data.astype('float64'), fft_size = fft_size, \n",
    "                                   step_size = step_size, log = True, thresh = spec_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recovered_audio_orig = invert_pretty_spectrogram(wav_spectrogram, fft_size = fft_size,\n",
    "                                            step_size = step_size, log = True, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bandwidth = 2048\n",
    "for n_mel_freq_components, bps in gen_params(bandwidth, trim=2):\n",
    "    sf = spect_bps / float(bps)\n",
    "    print (n_mel_freq_components, bps, sf)\n",
    "    mel_filter, mel_inversion_filter = create_mel_filter(fft_size = fft_size,\n",
    "                                                        n_freq_components = n_mel_freq_components,\n",
    "                                                        start_freq = start_freq,\n",
    "                                                        end_freq = end_freq)\n",
    "    mel_spec = make_mel(wav_spectrogram, mel_filter, shorten_factor = sf)\n",
    "    mel_inverted_spectrogram = mel_to_spectrogram(mel_spec, mel_inversion_filter,\n",
    "                                                spec_thresh=spec_thresh,\n",
    "                                                shorten_factor=sf)\n",
    "    inverted_mel_audio = invert_pretty_spectrogram(np.transpose(mel_inverted_spectrogram), fft_size = fft_size,\n",
    "                                            step_size = step_size, log = True, n_iter = 10)\n",
    "    inverted_mel_audio = (inverted_mel_audio /np.max(np.abs(inverted_mel_audio))*32767).astype('int16')\n",
    "    wavfile.write(data=inverted_mel_audio, filename='reconstructions/bush_%04d_%04d_%04d.wav'%(bandwidth, n_mel_freq_components, bps), rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=10)\n",
    "bandwidth = 2048\n",
    "for n_mel_freq_components, bps in gen_params(bandwidth, trim=2)[9:12]:\n",
    "    sf = spect_bps / float(bps)\n",
    "    print (n_mel_freq_components, bps, sf)\n",
    "    mel_filter, mel_inversion_filter = create_mel_filter(fft_size = fft_size,\n",
    "                                                        n_freq_components = n_mel_freq_components,\n",
    "                                                        start_freq = start_freq,\n",
    "                                                        end_freq = end_freq)\n",
    "    \n",
    "#     fig, ax = plt.subplots(nrows=2,ncols=1, figsize=(20,4))\n",
    "#     ax[0].matshow(np.transpose(mel_filter),cmap=plt.cm.afmhot, interpolation='nearest', aspect='auto')\n",
    "#     ax[0].set_title('mel Filter')\n",
    "#     ax[1].matshow(mel_inversion_filter,cmap=plt.cm.afmhot, interpolation='nearest', aspect='auto')\n",
    "#     ax[1].set_title('mel Inversion Filter')\n",
    "    \n",
    "#     print mel_filter.shape, mel_filter\n",
    "#     print mel_inversion_filter.shape, mel_inversion_filter\n",
    "#     print mel_inversion_filter.sum(axis=1).shape, mel_inversion_filter.sum(axis=1)\n",
    "#     print np.nonzero(mel_inversion_filter.sum(axis=1)==0), np.sum(mel_inversion_filter.sum(axis=1)==0)\n",
    "#     plt.hist(mel_inversion_filter[:])\n",
    "#     plt.hist(mel_filter[:])\n",
    "#     mel_spec =np.transpose(mel_filter).dot(np.transpose(wav_spectrogram))\n",
    "# #     print mel_spec.shape, mel_spec\n",
    "#     mel_spec = scipy.ndimage.zoom(mel_spec.astype('float32'), [1, 1./shorten_factor]).astype('float16')\n",
    "# #     print mel_spec.shape, mel_spec\n",
    "#     mel_spec = mel_spec[:,1:-1] # a little hacky but seemingly needed for clipping \n",
    "# #     print mel_spec.shape, mel_spec\n",
    "    \n",
    "    \n",
    "    mel_spec = make_mel(wav_spectrogram, mel_filter, shorten_factor = sf)\n",
    "    \n",
    "#     print mel_spec.shape, mel_spec\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,4))\n",
    "    cax = ax.matshow(mel_spec, interpolation='nearest', aspect='auto', cmap=plt.cm.afmhot, origin='lower')\n",
    "    fig.colorbar(cax)\n",
    "    plt.title('mel Spectrogram' + str((n_mel_freq_components, bps, sf)))\n",
    "    \n",
    "#     mel_inverted_spectrogram = mel_to_spectrogram(mel_spec, mel_inversion_filter,\n",
    "#                                                 spec_thresh=spec_thresh,\n",
    "#                                                 shorten_factor=sf)\n",
    "#     inverted_mel_audio = invert_pretty_spectrogram(np.transpose(mel_inverted_spectrogram), fft_size = fft_size,\n",
    "#                                             step_size = step_size, log = True, n_iter = 10)\n",
    "#     wavfile.write(data=inverted_mel_audio, filename='reconstructions/bush_%04d_%04d_%04d.wav'%(bandwidth, n_mel_freq_components, bps), rate=rate)\n",
    "#     IPython.display.Audio(data=inverted_mel_audio, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(inverted_mel_audio/np.max(np.abs(inverted_mel_audio)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
